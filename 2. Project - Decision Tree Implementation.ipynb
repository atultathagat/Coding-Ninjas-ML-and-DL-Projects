{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset as pandas dataframe and splitting it into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('iris.csv') #reading the dataset\n",
    "train_df,test_df=train_test_split(df,random_state=0) #splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if the data is pure or not i.e. it contains only one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pure(df):\n",
    "    unique_values=len(np.unique(df.iloc[:,-1])) #finding the length of unique classes in the data\n",
    "    if unique_values==1: #if length of unique classes is 1, the data is pure and it contains only one class\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the data - finding the majority class in the data (the class having maximum data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df):\n",
    "    species,counts=np.unique(df.iloc[:,-1],return_counts=True) #finding the unique classes and their count in data\n",
    "    index=np.argmax(counts) # finding the index of the class which has maximum count\n",
    "    return species[index]  #returning the class with mamximum count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the potential splits (the values on which we can perform split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(df):\n",
    "    potential_splits={} # this dictionary contains columns number as key and a list containing potential splits as value\n",
    "    columns=df.columns\n",
    "    for j in range(len(columns)-1):\n",
    "        column_values=np.unique(df[columns[j]].values) #finding unique values in a column j\n",
    "        potential_splits[j]=[]\n",
    "        for i in range(1,len(column_values)):\n",
    "            potential_splits[j].append((column_values[i]+column_values[i-1])/2) #finding all potential splits for column j\n",
    "    return potential_splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits=get_potential_splits(train_df) #getting potential splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data points on the basis of potential split of a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df,split_column,split_value):\n",
    "    columns=df.columns\n",
    "    left_df=df[df[columns[split_column]]<=split_value] #getting the data points in which column values are less than or equal to split value\n",
    "    right_df=df[df[columns[split_column]]>split_value] #getting the data points in which column values are greater than split value\n",
    "    return left_df,right_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating entropy of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(df):\n",
    "    counts=np.unique(df.iloc[:,-1],return_counts=True)[1] #getting counts of all the classes in the data\n",
    "    probabilities=counts/counts.sum() #finding probability of each data points\n",
    "    entropy=(-probabilities*np.log(probabilities)).sum() #calculating entropy\n",
    "    return entropy #returning entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating gain ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain_ratio(df,left_df,right_df):\n",
    "    entropy_left=calculate_entropy(left_df) #getting entropy of data points which are in left half\n",
    "    entropy_right=calculate_entropy(right_df) #getting entropy of data points which are in right half\n",
    "    d1=len(left_df)\n",
    "    d2=len(right_df)\n",
    "    d=d1+d2\n",
    "    entropy_before=calculate_entropy(df) #calculating data points before split\n",
    "    entropy_after=(d1/d)*entropy_left+(d2/d)*entropy_right #calculating overall entropy after split\n",
    "    info_gain=entropy_before-entropy_after #calculating information gain\n",
    "    split_info=-(d1/d)*np.log(d1/d)-d2/d*np.log(d2/d) #calculating split info\n",
    "    gain_ratio=info_gain/split_info #calculating gain ratio\n",
    "    return gain_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting best split (finding the column number and split value of that column on which if data is splitted then the gain ratio is maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(df,potential_splits):\n",
    "    potential_splits=get_potential_splits(df) # getting potential splits\n",
    "    max_gain_ratio=-1 # it holds the maximum gain ratio\n",
    "    best_split_column=-1 #it holds the best column number on which gain ratio is maximum when splitted\n",
    "    best_split_value=-1 #it holds the best split value on which gain ratio is maximum when splitted\n",
    "    for column in potential_splits:\n",
    "        for split_value in potential_splits[column]:\n",
    "            left_df,right_df=split(df,column,split_value) #splitting the data points\n",
    "            gain_ratio=calculate_gain_ratio(df,left_df,right_df) #finding gain ratio for a particular split\n",
    "            if gain_ratio>max_gain_ratio: #finding the maximum gain ratio\n",
    "                max_gain_ratio=gain_ratio\n",
    "                best_split_value=split_value\n",
    "                best_split_column=column\n",
    "    return best_split_column,best_split_value,max_gain_ratio   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the decision tree steps and building actual decision tree (getting a dictionary which contains at each level, on which feature and on which value the data should be splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df,potential_split,level,max_level=3):\n",
    "    if level>0:\n",
    "        print()\n",
    "    if len(df)==0:\n",
    "        return None\n",
    "    print('Level', level)\n",
    "    species,counts=np.unique(df.iloc[:,-1],return_counts=True)\n",
    "    #printing the decision tree in the required format\n",
    "    for i in range(len(species)):\n",
    "        print('Count of',species[i],'=',counts[i]) #printing unique classes in data points and its counts\n",
    "    current_entropy=calculate_entropy(df) #finding current entropy for each data points\n",
    "    print('Current Entropy is',current_entropy)\n",
    "    if is_pure(df) or level==max_level: #if data point is pure i.e. only one class is present or maximum level is reached, predicting the class based on majority votes\n",
    "        print('Reached Leaf Node')\n",
    "        return classify(df)\n",
    "    else:\n",
    "        best_split_column,best_split_value,max_gain_ratio=get_best_split(df,potential_splits) #finding the split column and split value for which gain ratio is maximum\n",
    "        feature_name=df.columns[best_split_column]\n",
    "        tree_dict={}\n",
    "        key=str(feature_name)+'  <= '+str(best_split_value)\n",
    "        tree_dict[key]=[]\n",
    "        print('Splitting on feature ',feature_name,'with gain ratio ',max_gain_ratio)\n",
    "        left_df,right_df=split(df,best_split_column,best_split_value)\n",
    "        left_dict=fit(left_df,potential_split,level+1)\n",
    "        right_dict=fit(right_df,potential_split,level+1)\n",
    "        if not left_dict is None:\n",
    "            tree_dict[key].append(left_dict)\n",
    "        if not right_dict is None:\n",
    "            tree_dict[key].append(right_dict)\n",
    "        return tree_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of setosa = 37\n",
      "Count of versicolor = 34\n",
      "Count of virginica = 41\n",
      "Current Entropy is 1.0956714129052516\n",
      "Splitting on feature  petal_length with gain ratio  1.0\n",
      "\n",
      "Level 1\n",
      "Count of setosa = 37\n",
      "Current Entropy is 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of versicolor = 34\n",
      "Count of virginica = 41\n",
      "Current Entropy is 0.6887852792452958\n",
      "Splitting on feature  petal_length with gain ratio  0.7064313543656207\n",
      "\n",
      "Level 2\n",
      "Count of versicolor = 33\n",
      "Count of virginica = 3\n",
      "Current Entropy is 0.2868359830561607\n",
      "Splitting on feature  petal_width with gain ratio  0.643158422044091\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 32\n",
      "Current Entropy is 0.0\n",
      "Reached Leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 1\n",
      "Count of virginica = 3\n",
      "Current Entropy is 0.5623351446188083\n",
      "Reached Leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of versicolor = 1\n",
      "Count of virginica = 38\n",
      "Current Entropy is 0.11924692639624491\n",
      "Splitting on feature  petal_length with gain ratio  0.1861963514259986\n",
      "\n",
      "Level 3\n",
      "Count of versicolor = 1\n",
      "Count of virginica = 3\n",
      "Current Entropy is 0.5623351446188083\n",
      "Reached Leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of virginica = 35\n",
      "Current Entropy is 0.0\n",
      "Reached Leaf Node\n"
     ]
    }
   ],
   "source": [
    "# printing the steps of decision tree and storing the actual decision tree as a dictionary\n",
    "tree_dict=fit(train_df,potential_splits,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'petal_length  <= 2.35': ['setosa',\n",
       "  {'petal_length  <= 4.95': [{'petal_width  <= 1.65': ['versicolor',\n",
       "      'virginica']},\n",
       "    {'petal_length  <= 5.05': ['virginica', 'virginica']}]}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the actual decision tree\n",
    "tree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicing the class for a given single data point\n",
    "def predict_single_data_point(tree_dict,data):\n",
    "    key=list(tree_dict.keys())[0]\n",
    "    feature_name,_,value=key.split()\n",
    "    current_value=data[feature_name]\n",
    "    if current_value<=float(value):\n",
    "        residual_dict=tree_dict[key][0]\n",
    "    else:\n",
    "        residual_dict=tree_dict[key][1]\n",
    "    residual_dict    \n",
    "    if isinstance(residual_dict,dict):\n",
    "        return predict_single_data_point(residual_dict,data)\n",
    "    else:\n",
    "        return residual_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the class for all the data points\n",
    "def predict_all_data_points(tree_dict,test_df):\n",
    "    y_pred=[]\n",
    "    for i in range(len(test_df)):\n",
    "        y_pred.append(predict_single_data_point(tree_dict,test_df.iloc[i]))\n",
    "    return y_pred    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking performance of decision tree through confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred=predict_all_data_points(tree_dict,test_df)\n",
    "y_test=test_df['species']\n",
    "cm=confusion_matrix(y_test,y_pred) #getting confusion matrix\n",
    "print(cm) #printing confusion matrix\n",
    "sns.heatmap(cm,annot=True) #plotting confusion matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of decision tree: 97.37%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of decision tree:',\"{:.2%}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      0.94      0.97        16\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred)) #printing classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
